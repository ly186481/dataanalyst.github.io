<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Li's Data Analysis Workshop</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
							<header id="header">
								<a href="index.html" class="logo"><strong>Li's</strong> Data Analysis Workshop</a>
								<ul class="icons">
									<li><a href="https://github.com/ly186481" class="icon brands fa-github"><span class="label">github</span></a></li>
								</ul>
							</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h2>Machine Learning</h2>
									</header>
									<p>Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy</p>
									
									<hr class="major" />
								
									<h2>Lazy Learning-Classification Using Nearest Neighbors</h2>
									<p>Nearest Neighbors requires a distance function, or a formula that measures the similarity between two distances.
										kNN algorithm uses Euclidean distance, which is the distance one would measure if you could use a ruler to connect two points.
								
									</p>
									<p>k=1, 1NN, The one nearest neighbors type will classification-type the type of the subject. 1NN.
									</p>
									<p>k=3, 3NN, it performs a vote among the three nearest neighbors. The majority class among these neighbors will classify the subject. 
									</p>
									<p>Choosing an appropriate k.
										The balance between overfitting and underfitting the training data is a problem known as the bias-variance tradeoff.
										Choosing a large k reduces the impact or variance caused by noisy data, but can bias the learner such that it runs the risk of ignoring small, but important patterns.
										On the opposite, using single small k allow noisy data or outliers, to unduly influence the classification.
									</p>
									<p>k is set somewhere between 3-10. Commonly used to set k equal to the square root of the number of training examples.
										Other way is to approach test several k values on a variety of test datasets and choose the one that delivers the best classification performance.
									</p>
									<p><b>Diagnosing breast cancer with the kNN algorithm</b>.</p>
									<p>Detecting cancer by applying the kNN algorithm to measurements of biopsied cells from women with abnormal breast masses.
										<ul>
											<li>Step 1 - Collecting Data,
												<a href="https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic">"Breast Cancer Wisconsin Diagnostic""</a>.
											</li>
											<li>Step 2 - Exploring and preparing the data,</li>
											<pre><code>
<b>#sample, Lazy learning kNN</b>
wbcd <- read.csv("wisc_bc_data.csv",stringsAsFactors = FALSE)

#exclude ID column
wbcd <- wbcd[-1]

#browse the structure of diagnosis column
table(wbcd$diagnosis)

#label B,M
wbcd$diagnosis <- factor(wbcd$diagnosis, levels=c("B","M"),
                         labels=c("Benign","Malignant"))

round(prop.table(table(wbcd$diagnosis))*100,digits=1)

summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])

#smoothness and radius has big gap in distance, so it need normalization
normalize <- function(x){
  return((x-min(x))/(max(x)-min(x)))
  }

#test normalize function
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))

wbcd_n <- as.data.frame(lapply(wbcd[2:31],normalize))
summary(wbcd_n$area_mean)

wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]

#training kNN model, store these class labels in factor vectors
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]

</code></pre>

											<li>Step 3 - training a model on the data</li>
<pre><code>
install.packages("class")
library(class)

install.packages("gmodels")
library(gmodels)

wbcd_test_pred <- knn(train = wbcd_train,
                      test = wbcd_test,
                      cl = wbcd_train_labels,
                      k = 21)

		</code></pre>	
		
											<li>Step 4 - evaluating model performance</li>
<pre><code>
CrossTable(x=wbcd_test_labels,
		y=wbcd_test_pred,
		prop.chisq = FALSE)

</code></pre>

<li>Step 5 - Improving model performance</li>
<li> To improve performance, approaching althernaitive method for rescaling numeric features and trying several different values for k.
	Applying z-score normalization.
</li>

<pre><code>
#rescaling with z-score standardization, mean should be always 0.
wbcd_z <- as.data.frame(scale(wbcd[-1]))
summary(wbcd_z$area_mean)
	
wbcd_train <- wbcd_z[1:469, ]
wbcd_test <- wbcd_z[470:569, ]
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_labels, k=21)
CrossTable(x=wbcd_test_labels,y=wbcd_test_pred, prop.chisq = FALSE)

</code></pre>

<pre><code>
#try several different values of k
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
	
k_values <- c(1, 5, 11, 15, 21, 27)
	
for(k_val in k_values){
wbcd_test_pred <- knn(train = wbcd_train,
						test = wbcd_test, 
						cl=wbcd_train_labels,
						k=k_val)

#To see the result of my knn 
CrossTable (x = wbcd_test_labels, 
			y=wbcd_test_pred, 
			prop.chiaq=FALSE)
}
	

</code></pre>
												
											

										</ul>


									</p>
									
									<hr class="major" />

									<h2>Rescaling Features</h2>
									<p><b>Min-Max Normalization</b>. This process transforms a feature such that all of its values fall in a range between 0 and 1.</p>

									<p><b>z-score standardization</b>. It subtracts the mean value of feature X and divides by the standard deviation of X.</p>

									<hr class="major" />

									<h2>Lorem aliquam bibendum</h2>
									<p>Donec eget ex magna. Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fergiat. Pellentesque in mi eu massa lacinia malesuada et a elit. Donec urna ex, lacinia in purus ac, pretium pulvinar mauris. Curabitur sapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit.</p>
									<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis dapibus rutrum facilisis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam tristique libero eu nibh porttitor fermentum. Nullam venenatis erat id vehicula viverra. Nunc ultrices eros ut ultricies condimentum. Mauris risus lacus, blandit sit amet venenatis non, bibendum vitae dolor. Nunc lorem mauris, fringilla in aliquam at, euismod in lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In non lorem sit amet elit placerat maximus. Pellentesque aliquam maximus risus, vel sed vehicula.</p>

								</section>
					
					
					
					<ul class="pagination">
						
						<li><a href="ml.html" class="page active">1</a></li>
						<li><a href="ml2.html" class="page">2</a></li>
						<li><a href="#" class="page">3</a></li>
						
						
					</ul>
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Homepage</a></li>
									<li><a href="casestudy.html">Case Study</a></li>
									<li><a href="dataanalysis.html">Data Analysis</a></li>
									<li>
										<span class="opener">Method</span>
										<ul>
											<li><a href="ml.html">Machine Learning</a></li>
											<li><a href="bigdata.html">Big Data</a></li>
										</ul>
									<li>
										<span class="opener">Knowledge Collection</span>
										<ul>
											<li><a href="consumer.html">consumer</a></li>
											<li><a href="HR.html">Human Resources</a></li>
											<li><a href="finance.html">Finance</a></li>
											<li><a href="health.html">Health</a></li>
										</ul>
									</li>
								</ul>
							</nav>

							

							<!-- Section -->
							<section>
								<header class="major">
									<h2>Workshop</h2>
								</header>
								<div class="mini-posts">
									<article>
										<a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
									
								</div>
								<ul class="actions">
									<li><a href="#" class="button">More</a></li>
								</ul>
							</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>